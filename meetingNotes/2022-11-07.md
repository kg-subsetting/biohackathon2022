# Biohackathon-Europe 2022 Project 11 - Notes
## Links

- [HackMD notes](https://hackmd.io/@vfttImB6SdiREhh65hglIA/SykVQELBi/edit)
- [notes from 2021 (Barcelona)](https://hackmd.io/gHHasGifTEaDMdvM9LTxTQ)

# Third day 9th-Nov-2022

## Attendants
- Seyed
- Jose Labra
- Andra
- Ammar
- Carolina 

## Notes

- Explanation about wdsub
    -  Input JSON dumps
    -  Output: you can choose between JSON or Turtle
-  The dataset generated yesterday from Genewiki seems to generate only taxons...
    -  Maybe the reason is that the JSOn output generation has some bug
-  Ammar used the ShEx for the lipids with wdsub library and used it with the 2014...it took less than an hour
    -  64M zipped, 492 Mb unzipped
    -  Only contains the taxon entities...maybe the same bug?
    -  Upload the dataset of lipids to another Zenodo
- Andra:
    - wdsub seems to run
    - shape expressions with classes and identifiers...
    - error messages
        - somevalues/novalues are not implemented yet
        - geocoordinates which should not be in genewiki
        - took a long time: 
        - 14 hours more or less
        - 610Mb
    - Detect problems in wikidata
        - taxon is not a taxon but a taxon name
        - multiple wikidata items for the same taxon
            - problem with bacteria and viruses
        - targeted subsets
            - taxon subset...
- Carolina:
    - GeneWiki subset but seems to contain only taxons
        - Github: https://github.com/kg-subsetting/biohackathon2022/blob/main/examples/ShEx/geneWiki.shex 
    - Apply the subset to machine learning algorithm that she has (Case-Based reasoning).
        - Apply her algorithm to this subset for drug repurpusing. 
- Seyed:
    - Checking the number of extracted outputs 
    - WDF: Wikibase dump filter
        - Dumpformat = JSON
    - both tools miss some gene instances ~ 4000 instances
    - wdsub miss 600 more
    - List of items that are in one and not in the other
    - Analyzing accuracy, which is important
- Labra
    - Created the GeneWiki subset using the GeneWiki.shex using JSON output for 2018
    - Create the script to obtain
        - GeneWiki of 2018 in Turtle
        - GeneWiki of 2022 in Turtle
        - GeneWiki of 2022 in Json
        - Still running (more than 12 hours) 
    - Publish in Zenodeo 
- Possibilities to upload the datasets
    - github repo for datasets: https://github.com/kg-subsetting/datasets-biohackathon2022 
    -  Zenodo: already done, limit of 50G
    -  Dryad: maybe for the latest version for the paper, because the datasets are reviewed
    -  data.world
        -  Examples from book: https://data.world/swwo
    -  tryplydb ?
- Discuss the workflow and automate the creation of subset
    -  Wikidata Subsets as as Service
        -  Enter a entity schema and obtain a subset
    -  wdsub is a command line tool with docker support
        -  Andra was able to do it in a laptop (slimbook)
        -  We could wrap it into a web service
            -  It would be great to have a server host as WDumper
                -  https://wdumps.toolforge.org/dumps
    -  Options
        -  Command line
        -  Generic web service
        -  Pre-defined subsets
            - Fix set of curated shape expressions
                -  cron job to run that service...
            - Wikidata + quality control 
- Other tools apart from wdsub
    - Ammar reminds that he created a subset for lipids using pyshex and slurper

##### LipidMaps Wikidata Subset (BioHackathon 2021)

During the BioHackathon 2021, one of the use cases formulated to experiment with subsetting was about lipid chemical compounds [GitHub link](https://github.com/kg-subsetting/biohackathon2021/tree/main/use_cases/lipidmaps). 

The aim of this use case was to make a subset of Wikidata that contains all the chemical compounds having a LipidMaps ID. LipidMaps is an online gateway that provide access to lipid nomenclature, databases, tools, protocols, standards, and other resources serving the international lipid research community. It also supports the integrative systems-level analyses of multiomics measurements in human physiology and pathophysiology. Therfore, having a semantic knowledge graph of lipids from Wikidata can be valuable to empower lipids-related research.


For this use case, Shape Expressions (ShEx) language and SPARQL were used to extract lipids and related entities from Wikidata. A [Jupyter notebook](https://github.com/kg-subsetting/biohackathon2021/blob/main/use_cases/lipidmaps/wikidata-lipids-slurper.ipynb) was developed which uses [PyShEx](https://pypi.org/project/PyShEx/) Python library to subset the live wikidata knowledge graph. The ShEx expression (figure below) created for this purpose extracts the Wikidata entities having a LipidMaps ID, an InChi ID and an InChi key properies linked by the predicates wdt:P2063, wdt:P234, wdt:235 respectively. Moreover, the entity should be linked to a Taxon entity belonging to the class wd:Q16521.

One limitation to the used approach is the ungauranteed stability of the Wikidata SPARQL endpoint. Sometimes, a connection error occurs or a maximum number of requests is reached. The connection problems could be due to the high traffic load on the endpoint. One way to mitigate this is to use limit and offset in the SPARQL query that selects the entities for the slurper. Then, the query is executed in  a loop to fetch each batch. With this approach, the process can be restarted in the case of an error for only the small batch of entites. Thus, time will be saved.

Running the script took four hours on a personal laptop. That resulted in a 75MB ttl file (15MB zipped). Also, it is available for [download](https://github.com/kg-subsetting/biohackathon2021/blob/main/use_cases/lipidmaps/subset/lipids-subset.tar.gz?raw=true).



![](https://i.imgur.com/Xh4XPru.png)


# Second day 8th-Nov-2022

## Attendants
- Seyed
- Jose Labra
- Andra

## Notes
- Seyed, created a subset which contains instances of Genes, Proteins, etc. and put the output (turtle) in a Blazegraph 
    - Dumps from: 3 January 2022 [Link]( https://academictorrents.com/details/229cfeb2331ad43d4706efd435f6d78f40a3c438)
    - SPARQL counting: 
        - Gene: 1196517
        - Protein: 987614
        - Chemical compound: 1244866
        - Disease: 5512
- Andra [created an example](https://github.com/kg-subsetting/biohackathon2022/blob/main/examples/ShEx/gene.shex) of a ShEx to extract info related with Genes but that is more inclusive than just checking the P31 Q7187, including all things that have at least some specific properties...

```
<Gene> @<TypedGene> OR @<PropertyBasedGene>

<TypedGene> EXTRA p:P31 {
  p:P31 { ps:P31 [wd:Q7187]} 
}

<PropertyBasedGene> 
  { p:P351 { ps:P351 . } +  OR 
  { p:P353 { ps:P353 . } + OR 
  . . .
}

```

- Ammar is planning to work on a subset related with lipids using a ShEx like the following:

```
PREFIX xsd:    <http://www.w3.org/2001/XMLSchema#>
PREFIX :    <http://bigcat.unimaas.nl/>
PREFIX rdf:    <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs:    <http://www.w3.org/2000/01/rdf-schema#>
PREFIX wd:    <http://www.wikidata.org/entity/>
PREFIX wdt:    <http://www.wikidata.org/prop/direct/>

start= @:lipids OR @:taxon

:lipids {
   wdt:P2063 .+;
   wdt:P234 .+;
   wdt:P235 .+;
   wdt:P703 @:taxon +;
}

:taxon {
	wdt:P31 [wd:Q16521];
}
```

```
#!/bin/sh
Version=0.0.26
Dump2018=wikidata-20180115-all # Local Downloaded dump from Wikidata

Name=taxons
DumpFile=${Dump2018}
SchemaFormat=ShExC
DumpMode=OnlyMatched
DumpFormat=Turtle
docker run -d -v /home/labra/dumps:/data -v /home/labra/wdsubConfig/shex:/shex -v /home/labra/generatedDumps:/generatedDumps wesogroup/wdsub:${Version} dump -o /generatedDumps/${Name}.ttl.gz -s /shex/${Name}.shex /data/${DumpFile}.json.gz --dumpFormat ${DumpFormat} --dumpMode ${DumpMode} --schemaFormat ${SchemaFormat}
```

Ideas talking with Carolina during lunch
- Create a subset based on her [ShEx](https://github.com/kg-subsetting/biohackathon2022/blob/main/examples/ShEx/geneWiki.shex)
- Review JSON structure of the subsets 
- Once we get the subset, apply some Machine Learning algorithms...
    - Link prediction?
- We started to run wdsub using Carolina's ShEx which contains information about GeneWiki. The shape we used was [this one](https://github.com/kg-subsetting/biohackathon2022/blob/main/examples/ShEx/geneWiki.shex)
- [Link to some past results from Labra's students]( https://docs.google.com/document/d/1mxEo6y4IJjVpDK1nT2PvcvkFgvTCLBJax6WipTMXCUM/edit#heading=h.9ywt0nihccfc)
- 




# First day 7th-Nov-2022
## Attendants
- Jose Labra
- Andra Waagmeester
- Eric Prud'hommeaux
- Carolina Gonzalez
- Sayed Beghaei

## Notes

- During the break I met Egon and were talking about possibility of creating a subset about Chemistry
- Idea: prepare a tutorial to explain how to create subsets using wdsub
- Andra: plan for the week
    - Expectations
        - Finish the paper that we started last year
        - Create subsets for GeneWiki
        - What to do with the subset
            - Issue to solve: Where to store the created subset
                - [Dryad](https://datadryad.org/stash)
        - Seyed same expectations
        - Expressivity of wdsub is constrained by sequential processing for each line...it checks each item 

# Gameplan
* Andra: Revisit the wdsubset of genewiki subgraph
    * This involves support for qualifiers and references


Example of things supported in wdsub:

```
start = @<Gene> OR @<Disease> OR ...

<Gene> EXTRA wdt:P31 {
  wdt:P31   [ wd:Q7187 ....] ;
  # Don't follow this pattern: wdt:P31 . * ;
  wdt:P703  
  
  # References are supported but not validated
  :encodes  @<Protein> ;
  
  # Qualifiers...
  p:P166 { 
    ps:P166  @<Award>         ;
    pq:P585  xsd:dateTime   ? ; 
    pq:P1706 @<Researcher>  *
  } *

}



<Disiease> {

}

<Protein> { 
  wdt:p31 [....]
}
```



```
start = @<Gene_by_ontology> OR @<Gene_by_identifier>

<Gene_by_ontology> {
    p:P31 {
       ps:P31 [wd:Q7187] ;
       prov:wasDerivedFrom . ;
    }
    
    p:P703 {
        ps:P703 [wd:homo sapiens] ;
        prov:wasDerivedFrom . ;
     
    }
}

<Gene_by_identifier> {
    p:
}
```



Seyed's question: What is the difference between these (in terms of extracting subset via WDSub)?:
1)
```
start = @<Gene> OR @<Disease> OR <Protein>

<Gene> EXTRA wdt:P31 {
  wdt:P31   [ wd:Q7187] ;
}

<Disiease> {
    wdt:p31 [wd:Qabc]
}

<Protein> { 
  wdt:p31 [wd:Qijk]
}
```
and 2)
```
start = @<all>

<all> EXTRA wdt:P31 {
  wdt:P31   [ wd:Q7187, wd:Qabc, wd:Qijk] ;
}

```


- Meeting with virtual attendees, tomorrow at 10h CET

https://github.com/kg-subsetting/biohackathon2022

- Andra: will work on preparing some examples about GeneWiki
- Seyed: Check if the tool finnished and review the output of wdsub.
    - Report about the possible turtle output
- Carolina has some Shape Expressions about GeneWiki (add more properties)
- Labra will continue checking the tool and update docker image

```
run dump -s schema.shex --schemaFormat ShExC -o target/exampleReferences.ttl.gz input.json.gz --dumpMode OnlyMatched --dumpFormat Turtle
```

